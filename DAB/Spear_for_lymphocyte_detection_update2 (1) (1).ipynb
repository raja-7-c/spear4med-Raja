{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT6ZXg34HMt_",
        "outputId": "16b60468-7c63-41b4-d0dc-75519f01556b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VKovPQiYwypg"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "from skimage.exposure import rescale_intensity\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import data\n",
        "from skimage.color import rgb2hed, hed2rgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imageProcessing1(df):\n",
        "\n",
        "        #img = cv2.imread(df)\n",
        "        # Example IHC image\n",
        "        ihc_rgb = df#img\n",
        "\n",
        "        # Separate the stains from the IHC image\n",
        "        ihc_hed = rgb2hed(ihc_rgb)\n",
        "\n",
        "        # Create an RGB image for each of the stains\n",
        "        null = np.zeros_like(ihc_hed[:, :, 0])\n",
        "        ihc_h = hed2rgb(np.stack((ihc_hed[:, :, 0], null, null), axis=-1))\n",
        "\n",
        "        ihc_h = ihc_h*255      \n",
        "\n",
        "   \n",
        "        image1 = ihc_h.astype('uint8')\n",
        "   \n",
        "        # cv2.cvtColor is applied over the\n",
        "        # image input with applied parameters\n",
        "        # to convert the image in grayscale \n",
        "        image_result = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "        return image_result"
      ],
      "metadata": {
        "id": "oWmPoJpNluPS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaration of a simple preprocessor function.  Preprocessor functions are used to preprocess an instance before labeling it. We use @preprocessor(name,resources) decorator to declare a function as preprocessor."
      ],
      "metadata": {
        "id": "YDxPUdsLxw0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from spear.labeling import preprocessor\n",
        "\n",
        "#@preprocessor(name = \"noise_removal\")\n",
        "def imagePreProcessing(df):\n",
        "\n",
        "        img = cv2.imread(df)\n",
        "        #Noise Removing\n",
        "        image = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
        "        #Gaussian Blur\n",
        "        gaussian_3 = cv2.GaussianBlur(image, (9,9), 10.0) #unblur\n",
        "        image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n",
        "        #Laplacian Filter\n",
        "        #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
        "        #image = cv2.filter2D(image, -1, kernel)\n",
        "        return image"
      ],
      "metadata": {
        "id": "X8-l_FHCx5qG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@labeling_function(resources=dict(keywords=trigWord1),pre=[convert_to_lower],label=ClassLabels.SPAM)\n",
        "def LF1(c): \n",
        "    \n",
        "    #image = d\n",
        "    img = c\n",
        "    # applying different thresholding \n",
        "    # techniques on the input image\n",
        "    # Otsu's thresholding after Gaussian filtering\n",
        "    # Apply GaussianBlur to reduce image noise if it is required\n",
        "\n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    \n",
        "    thresh2 = 255-image_result\n",
        "\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "\n",
        "    # loop over the number of unique connected component labels, skipping\n",
        "    # over the first label (as label zero is the background)\n",
        "    for i in range(1, numLabels):\n",
        "        # extract the connected component statistics for the current label\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "    \n",
        "        # ensure the width, height, and area are all neither too small\n",
        "        # nor too big\n",
        "        #keepWidth = w > 5 and w < 30\n",
        "        #keepHeight = h > 5 and h < 30\n",
        "        #keepArea = area > 10\n",
        "\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2500\n",
        "        # ensure the connected component we are examining passes all\n",
        "        # three tests\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            # construct a mask for the current connected component and\n",
        "            # then take the bitwise OR with the mask       \n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "\n",
        "\n",
        "        # Multiple objects\n",
        "        #result = image.copy()\n",
        "        contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "        colour = (255, 0, 0)\n",
        "        thickness = 1\n",
        "        i = 0\n",
        "        \n",
        "        bounding_boxes = []\n",
        "       # Iterate through the contours and find bounding boxes\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            bounding_boxes.append([x, y, x+w, y+h])\n",
        "            #cv2.rectangle(result, (x, y), (x+w, y+h), colour, thickness)\n",
        "  \n",
        "\n",
        "    return bounding_boxes\n"
      ],
      "metadata": {
        "id": "YM1Nc5YtRod7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Select 100 random images from the range of image numbers\n",
        "random_indices = random.sample(range(500), 500)\n",
        "\n",
        "# Specify the folder path where the images should be saved\n",
        "folder_path = '/content/drive/MyDrive/CAGE-Unsupervised'\n",
        "\n",
        "# Iterate through the selected images\n",
        "for index in random_indices:\n",
        "    # Load the image using the index\n",
        "    image_path = 'image_{}.png'.format(index)\n",
        "    im = Image.open(image_path)\n",
        "    \n",
        "    #cv2.imwrite('temp.jpg',np.array(im))\n",
        "    #pre_processed = imagePreProcessing('temp.jpg')\n",
        "\n",
        "    pre_processed = imagePreProcessing(image_path)\n",
        "    processed1 = imageProcessing1(pre_processed)\n",
        "    bounding_boxes1 = LF1(processed1)\n",
        "\n",
        "    # Get the bounding boxes for the image\n",
        "    #bounding_boxes1 = LF1(im)\n",
        "    # Iterate through the bounding boxes\n",
        "    for i, box in enumerate(bounding_boxes1):\n",
        "        x1, y1, x2, y2 = box\n",
        "        # Crop the image to the bounding box\n",
        "        cropped_im = im.crop((x1, y1, x2, y2))\n",
        "        # Save the cropped image with a unique name\n",
        "        cropped_im.save(f\"{folder_path}/image-{index}_box_{i}.png\")"
      ],
      "metadata": {
        "id": "WggdHOqLFdl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}