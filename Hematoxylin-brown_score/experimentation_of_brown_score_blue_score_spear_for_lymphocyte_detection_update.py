# -*- coding: utf-8 -*-
"""Experimentation_of_Brown_score_Blue_score_Spear_for_lymphocyte_detection_update.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SMLFpn0Uy0-0Vj6ZF8HekTULnnjEOCJh
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
from skimage import io
from PIL import Image

# Read in image from path
path ="/content/image_2.png"
ihc_rgb = io.imread(path)
imgg = Image.open(path)
plt.imshow(imgg)

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import matplotlib.image as mpimg
from matplotlib import pyplot as plt
import seaborn as sns
import albumentations as A
from skimage.exposure import rescale_intensity


import numpy as np
import matplotlib.pyplot as plt

from skimage import data
from skimage.color import rgb2hed, hed2rgb

def imageProcessing2(df):

        #img = cv2.imread(df)
        # Example IHC image
        ihc_rgb = df#img

        # Separate the stains from the IHC image
        ihc_hed = rgb2hed(ihc_rgb)

        # Create an RGB image for each of the stains
        null = np.zeros_like(ihc_hed[:, :, 0])
        ihc_d = hed2rgb(np.stack((ihc_hed[:, :, 2], null, null), axis=-1))

        ihc_d = ihc_d*255      

   

        image1 = ihc_d.astype('uint8')
   
        # cv2.cvtColor is applied over the
        # image input with applied parameters
        # to convert the image in grayscale 
        image_result = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)


        return image_result

"""Declaration of a simple preprocessor function.  Preprocessor functions are used to preprocess an instance before labeling it. We use @preprocessor(name,resources) decorator to declare a function as preprocessor."""

#from spear.labeling import preprocessor

#@preprocessor(name = "noise_removal")
def imagePreProcessing(df):

        img = cv2.imread(df)
        #Noise Removing
        image = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)
        #Gaussian Blur
        gaussian_3 = cv2.GaussianBlur(image, (9,9), 10.0) #unblur
        image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)
        #Laplacian Filter
        #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter
        #image = cv2.filter2D(image, -1, kernel)
        return image

pre_processed = imagePreProcessing("/content/image_2.png")

"""This is only hematoxylin-channel of image"""

processed2 = imageProcessing2(pre_processed) 
plt.imshow(processed2)
plt.show()

#@labeling_function(resources=dict(keywords=trigWord1),pre=[convert_to_lower],label=ClassLabels.SPAM)
def LF2(c,d): 
    
    image = d
    img = c
    # applying different thresholding 
    # techniques on the input image
    # Otsu's thresholding after Gaussian filtering
    # Apply GaussianBlur to reduce image noise if it is required

    blur = img  #cv2.GaussianBlur(img,(5,5),0)
    #image_result = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 81, 40)

    otsu_threshold, image_result = cv2.threshold(
         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)
    
    thresh2 = 255-image_result

    # Use morphological operations to clean up the image
    #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    #thresh2 = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernel)

    output = cv2.connectedComponentsWithStats(thresh2)
    (numLabels, labels, stats, centroids) = output
    mask = np.zeros(thresh2.shape, dtype="uint8")

    # loop over the number of unique connected component labels, skipping
    # over the first label (as label zero is the background)
    for i in range(1, numLabels):
        # extract the connected component statistics for the current label
        x = stats[i, cv2.CC_STAT_LEFT]
        y = stats[i, cv2.CC_STAT_TOP]
        w = stats[i, cv2.CC_STAT_WIDTH]
        h = stats[i, cv2.CC_STAT_HEIGHT]
        area = stats[i, cv2.CC_STAT_AREA]


        # consider the contour properties: aspect ratio, extent, or solidity
        aspect_ratio = float(w) / h
        extent = float(area) / (w * h)
        #solidity = float(area) / cv2.contourArea(cv2.findContours(labels == i, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)[0][0])
    
    
        # ensure the width, height, and area are all neither too small
        # nor too big
        #keepWidth = w > 5 and w < 30
        #keepHeight = h > 5 and h < 30
        #keepArea = area > 10

        keepWidth = w > 10 and w < 88
        keepHeight = h > 10 and h < 88
        keepArea = area > 200

        # consider the aspect ratio, extent, and solidity of the contours
        keepAspectRatio = aspect_ratio > 0.2 and aspect_ratio < 1.8
        keepExtent = extent > 0.3 and extent < 0.8
        #keepSolidity = solidity > 0.7
        # ensure the connected component we are examining passes all
        # three tests
        if all((keepWidth, keepHeight, keepArea, keepAspectRatio, keepExtent)):
            # construct a mask for the current connected component and
            # then take the bitwise OR with the mask       
            componentMask = (labels == i).astype("uint8") * 1
            mask = cv2.bitwise_or(mask, componentMask)


        # Multiple objects
        result = image.copy()
        contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours = contours[0] if len(contours) == 2 else contours[1]
        colour = (255, 0, 0)
        thickness = 1
        i = 0
        
        bounding_boxes = []
       # Iterate through the contours and find bounding boxes
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            bounding_boxes.append([x, y, x+w, y+h])
            cv2.rectangle(result, (x, y), (x+w, y+h), colour, thickness)
  

    return result, bounding_boxes

result, bounding_boxes2 = LF2(processed2, pre_processed)

"""The bounding boxes on H-channel of image"""

plt.imshow(result)

bounding_boxes2

import numpy as np
import matplotlib.pyplot as plt
from skimage import io

ihc_rgb = io.imread(path)

# Separate the stains from the IHC image
ihc_hed = rgb2hed(ihc_rgb)

# Create an RGB image for the DAB stain
null = np.zeros_like(ihc_hed[:, :, 0])
ihc_d = hed2rgb(np.stack((null, null, ihc_hed[:, :, 2]), axis=-1))

# Display DAB stain
plt.imshow(ihc_d)
plt.title("DAB")
plt.axis('off')
plt.show()

"""Bounding boxes from h-based translated to dab-based image to calculate brown score"""

from PIL import Image
from matplotlib.patches import Rectangle

def draw_bounding_boxes(ihc_d, bounding_boxes, output_path):
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.imshow(ihc_d)
    for bbox in bounding_boxes:
        x1, y1, x2, y2 = bbox
        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
    plt.axis('off')  # remove axis
    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
    im = Image.open(output_path)
    im = im.resize((267,267), Image.ANTIALIAS)
    im.save(output_path)

bounding_boxes = bounding_boxes2

draw_bounding_boxes(ihc_d, bounding_boxes, 'output.jpg')

from PIL import Image
def get_brown_score(im, x1, y1, x2, y2):
    # Crop image to bounding box
    crop_im = im.crop((x1, y1, x2, y2))
    
    # Convert image to RGB
    crop_im = crop_im.convert("RGB")
    
    # Initialize brown pixel count
    brown_pixels = 0
    
    # Iterate over all pixels in the bounding box
    for x in range(crop_im.size[0]):
        for y in range(crop_im.size[1]):
            # Get RGB values of the pixel
            r, g, b = crop_im.getpixel((x, y))
            
            # Check if pixel is brown (within a certain range of R, G, B values)
            if 128 <= r <= 255 and 0 <= g <= 128 and 0 <= b <= 128:
                brown_pixels += 1
    
    # Calculate brown score (ratio of brown pixels to total pixels)
    brown_score = brown_pixels / (crop_im.size[0] * crop_im.size[1])
    
    return brown_score

def draw_bounding_boxes(ihc_d, bounding_boxes, output_path):
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.imshow(ihc_d)
    for bbox in bounding_boxes:
        x1, y1, x2, y2 = bbox
        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
    plt.axis('off')  # remove axis
    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
    im = Image.open(output_path)
    im = im.resize((267,267), Image.ANTIALIAS)
    im.save(output_path)
    brown_scores = []
    for bbox in bounding_boxes:
        x1, y1, x2, y2 = bbox
        brown_score = get_brown_score(im, x1, y1, x2, y2)
        brown_scores.append(brown_score)
        print(f"Bounding box {bbox} has brown score of {brown_score}")
    return brown_scores

bounding_boxes = bounding_boxes2

brown_scores = draw_bounding_boxes(ihc_d, bounding_boxes, 'output.jpg')

import numpy as np
import matplotlib.pyplot as plt
from skimage import io
from PIL import Image

#folder_path = '/content/drive/MyDrive/Hematoxylin-Brown-Score/raw-images2'

def get_brown_score(im, x1, y1, x2, y2):
    # Crop image to bounding box
    crop_im = im.crop((x1, y1, x2, y2))
    
    # Convert image to RGB
    crop_im = crop_im.convert("RGB")
    
    # Initialize brown pixel count
    brown_pixels = 0
    
    # Iterate over all pixels in the bounding box
    for x in range(crop_im.size[0]):
        for y in range(crop_im.size[1]):
            # Get RGB values of the pixel
            r, g, b = crop_im.getpixel((x, y))
            
            # Check if pixel is brown (within a certain range of R, G, B values)
            if 128 <= r <= 255 and 0 <= g <= 128 and 0 <= b <= 128:
                brown_pixels += 1
    
    # Calculate brown score (ratio of brown pixels to total pixels)
    brown_score = brown_pixels / (crop_im.size[0] * crop_im.size[1])
    
    return brown_score




for i in range(500):
    # Read in image from path
    path =f"/content/image_{i}.png"
    ihc_rgb = io.imread(path)
    im = Image.open(path)
    # Separate the stains from the IHC image
    ihc_hed = rgb2hed(ihc_rgb)

    # Create an RGB image for the DAB stain
    null = np.zeros_like(ihc_hed[:, :, 0])
    ihc_d = hed2rgb(np.stack((null, null, ihc_hed[:, :, 2]), axis=-1))

    output_path1 = f"output1_{i}.jpg"
    

    pre_processed = imagePreProcessing(path)
    processed2 = imageProcessing2(pre_processed)
    result, bounding_boxes1 = LF2(processed2,pre_processed)
    bounding_boxes_b = bounding_boxes1

    brown_scores = draw_bounding_boxes(ihc_d, bounding_boxes_b, output_path1)
    
    bounding_boxes = []
    for j in range(len(bounding_boxes_b)):
        
        if brown_scores[j] > 0.09:
            bounding_boxes.append(bounding_boxes_b[j])



    print(bounding_boxes)
    # Plot the image
    fig, ax = plt.subplots()
    ax.imshow(im)

    # Draw rectangles for each bounding box
    for bb in bounding_boxes:
        rect = Rectangle((bb[0], bb[1]), bb[2]-bb[0], bb[3]-bb[1], linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

    plt.show()
    # Iterate through the bounding boxes
    for j, box in enumerate(bounding_boxes):
        x1, y1, x2, y2 = box
        # Crop the image to the bounding box
        cropped_im = im.crop((x1, y1, x2, y2))
        # Save the cropped image with a unique name
        #cropped_im.save(f"{folder_path}/image-{i}_box_{j}.png")