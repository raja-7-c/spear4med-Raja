{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKovPQiYwypg"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "from skimage.exposure import rescale_intensity\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import data\n",
        "from skimage.color import rgb2hed, hed2rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDxPUdsLxw0q"
      },
      "source": [
        "Declaration of a simple preprocessor function.  Preprocessor functions are used to preprocess an instance before labeling it. We use @preprocessor(name,resources) decorator to declare a function as preprocessor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8-l_FHCx5qG"
      },
      "outputs": [],
      "source": [
        "from spear.labeling import preprocessor\n",
        "\n",
        "@preprocessor()\n",
        "def imagePreProcessing(df):\n",
        "\n",
        "        img = cv2.imread(df)\n",
        "        #Noise Removing\n",
        "        image = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
        "        #Gaussian Blur\n",
        "        gaussian_3 = cv2.GaussianBlur(image, (9,9), 10.0) #unblur\n",
        "        image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n",
        "        #Laplacian Filter\n",
        "        #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
        "        #image = cv2.filter2D(image, -1, kernel)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryIAbJ3MhAUA"
      },
      "outputs": [],
      "source": [
        "from spear.labeling import labeling_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLOPXaHJeFd5"
      },
      "outputs": [],
      "source": [
        "@roi_selection(pre=[imagePreProcessing])\n",
        "def LF1(c):\n",
        "    # input image\n",
        "    ihc_rgb = c\n",
        "\n",
        "    # Separate the stains from the IHC image\n",
        "    ihc_hed = rgb2hed(ihc_rgb)\n",
        "\n",
        "    # Create an RGB image for each of the stains\n",
        "    null = np.zeros_like(ihc_hed[:, :, 0])\n",
        "    ihc_h = hed2rgb(np.stack((ihc_hed[:, :, 0], null, null), axis=-1))\n",
        "    ihc_h = ihc_h*255      \n",
        "    image1 = ihc_h.astype('uint8')\n",
        "   \n",
        "    # cv2.cvtColor is applied over the\n",
        "    # image input with applied parameters\n",
        "    # to convert the image in grayscale \n",
        "    img = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply GaussianBlur to reduce image noise if it is required\n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    # Otsu's thresholding after Gaussian filtering\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    # Invert the image\n",
        "    thresh2 = 255-image_result\n",
        "    # Get connected components\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    # Iterate over the number of unique connected component labels, skipping\n",
        "    # over the first label (as label zero is the background)\n",
        "    for i in range(1, numLabels):\n",
        "        # extract the connected component statistics for the current label\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        # ensure the width, height, and area are all neither too small\n",
        "        # nor too big\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        # ensure the connected component we are examining passes all\n",
        "        # three tests\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            # construct a mask for the current connected component and\n",
        "            # then take the bitwise OR with the mask\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    # Find contours of the mask        \n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    # Iterate through the contours and find bounding boxes\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c_jz9X_WFtm"
      },
      "outputs": [],
      "source": [
        "@roi_selection(pre=[imagePreProcessing])\n",
        "def LF2(c):\n",
        "    ihc_rgb = c\n",
        "\n",
        "    # Separate the stains from the IHC image\n",
        "    ihc_hed = rgb2hed(ihc_rgb)\n",
        "\n",
        "    # Create an RGB image for each of the stains\n",
        "    null = np.zeros_like(ihc_hed[:, :, 0])\n",
        "    ihc_d = hed2rgb(np.stack((ihc_hed[:, :, 2], null, null), axis=-1))\n",
        "\n",
        "    ihc_d = ihc_d*255      \n",
        "\n",
        "   \n",
        "\n",
        "    image1 = ihc_d.astype('uint8')\n",
        "    # cv2.cvtColor is applied over the\n",
        "    # image input with applied parameters\n",
        "    # to convert the image in grayscale \n",
        "    img = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    thresh2 = 255-image_result\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    for i in range(1, numLabels):\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSf5WsZWcdgb"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[imagePreProcessing])\n",
        "def LF3(c):\n",
        "    ihc_rgb = c\n",
        "\n",
        "    # Separate the stains from the IHC image\n",
        "    ihc_hed = rgb2hed(ihc_rgb)\n",
        "\n",
        "    # Create an RGB image for each of the stains\n",
        "    null = np.zeros_like(ihc_hed[:, :, 0])\n",
        "    # Rescale hematoxylin and DAB channels and give them a fluorescence look\n",
        "    h = rescale_intensity(ihc_hed[:, :, 0], out_range=(0, 1),\n",
        "                      in_range=(0, np.percentile(ihc_hed[:, :, 0], 99)))\n",
        "    d = rescale_intensity(ihc_hed[:, :, 2], out_range=(0, 1),\n",
        "                      in_range=(0, np.percentile(ihc_hed[:, :, 2], 99)))\n",
        "        \n",
        "\n",
        "    # Cast the two channels into an RGB image, as the blue and green channels respectively\n",
        "    zdh = np.dstack((null, d, h))\n",
        "\n",
        "    zdh = zdh*255      \n",
        "\n",
        "\n",
        "    image1 = zdh.astype('uint8')\n",
        "   \n",
        "    # cv2.cvtColor is applied over the\n",
        "    # image input with applied parameters\n",
        "    # to convert the image in grayscale \n",
        "    img = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    \n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    thresh2 = 255-image_result\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    for i in range(1, numLabels):\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlFiie-geE30"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[imagePreProcessing])\n",
        "def LF4(c):\n",
        "    image = c\n",
        "    # Split\n",
        "    red = img[:, :, 0]\n",
        "\n",
        "    image_result = red*255\n",
        "    \n",
        "    img = image_result\n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    thresh2 = 255-image_result\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    for i in range(1, numLabels):\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR0aXHAOgM3B"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[imagePreProcessing])\n",
        "def LF5(c):\n",
        "    image = c\n",
        "    # Split\n",
        "    green = img[:, :, 1]\n",
        "\n",
        "    image_result = green*255\n",
        "    \n",
        "    img = image_result\n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    thresh2 = 255-image_result\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    for i in range(1, numLabels):\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwJFEwdPgOzS"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[imagePreProcessing])\n",
        "def LF6(c):\n",
        "    image = c\n",
        "    # Split\n",
        "    blue = img[:, :, 2]\n",
        "\n",
        "    image_result = blue*255\n",
        "    \n",
        "    img = image_result\n",
        "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "    otsu_threshold, image_result = cv2.threshold(\n",
        "         blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,)\n",
        "    thresh2 = 255-image_result\n",
        "    output = cv2.connectedComponentsWithStats(thresh2)\n",
        "    (numLabels, labels, stats, centroids) = output\n",
        "    mask = np.zeros(thresh2.shape, dtype=\"uint8\")\n",
        "    for i in range(1, numLabels):\n",
        "        x = stats[i, cv2.CC_STAT_LEFT]\n",
        "        y = stats[i, cv2.CC_STAT_TOP]\n",
        "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        keepWidth = w > 20\n",
        "        keepHeight = h > 20\n",
        "        keepArea = 100 < area < 2000\n",
        "        if all((keepWidth, keepHeight, keepArea)):\n",
        "            componentMask = (labels == i).astype(\"uint8\") * 1\n",
        "            mask = cv2.bitwise_or(mask, componentMask)\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    bounding_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append([x, y, x+w, y+h])\n",
        "    return bounding_boxes"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b671c20432fcd147198c92e7f072af9e705f087eb990bee22b07f08caab9f630"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
